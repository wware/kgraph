services:
  api:
    build:
      context: .
      dockerfile: kgserver/Dockerfile
    stdin_open: true
    tty: true
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/kgserver
      BUNDLE_PATH: /bundle
      # Chainlit (mounted at /chat on same server)
      MCP_SSE_URL: ${MCP_SSE_URL:-http://mcpserver:8001/sse}
      LLM_PROVIDER: ${LLM_PROVIDER:-anthropic}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      ANTHROPIC_MODEL: ${ANTHROPIC_MODEL:-claude-sonnet-4-6}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      EXAMPLES_FILE: /app/chainlit/examples.yaml
    volumes:
      - ./medlit_bundle:/bundle:ro
      - ./chainlit/examples.yaml:/app/chainlit/examples.yaml:ro
    #  # - /home/wware/S.zip:/bundle/S.zip:ro
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - kgserver-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    profiles: ["api"]

  # MCP server: can take 30â€“60s to start on small droplets (heavy Python imports: Strawberry, SQLAlchemy, storage)
  mcpserver:
    build:
      context: .
      dockerfile: kgserver/Dockerfile
    command: ["python", "-m", "uvicorn", "mcp_main:app", "--host", "0.0.0.0", "--port", "8001"]
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/kgserver
    ports:
      - "8001:8001"
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - kgserver-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/health')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    profiles: ["api"]

  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    command:
      - jupyter
      - lab
      - --ip=0.0.0.0
      - --port=8888
      - --no-browser
      - --ServerApp.token=
      - --ServerApp.password=
      - --ServerApp.base_url=/jupyter
      - --ServerApp.allow_origin=*
      - --ServerApp.allow_root=True
    ports:
      - "127.0.0.1:8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/notebooks
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/kgserver
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - kgserver-network
    restart: unless-stopped
    profiles: ["api", "jupyter"]

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ~/ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "/bin/ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - kgserver-network
    # CPU-only configuration - no GPU required
    # Models will be pulled on first use or manually via:
    # docker exec -it med-lit-ollama ollama pull nomic-embed-text
    profiles: ["ollama", "jupyter"]

  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: kgserver
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d kgserver"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - kgserver-network
    profiles: ["api", "storage", "jupyter"]

volumes:
  pgdata:
    driver: local

networks:
  kgserver-network:
    driver: bridge
